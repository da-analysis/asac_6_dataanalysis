import streamlit as st
from langchain.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import json
import re
import os
import pickle

config = {
    "api_key": st.secrets["api"]["api_key"],
    "model": "gpt-4o-mini"
}

class RAGTextBase:
    def __init__(self, config):
        """RAG í…ìŠ¤íŠ¸ ëª¨ë¸ì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
        self.config = config
        self.embeddings = OpenAIEmbeddings(api_key=config["api_key"])
        self.llm = ChatOpenAI(model=config["model"], api_key=config["api_key"])

        # ChromaDB ê²½ë¡œ ì„¤ì •
        vector_store_path = "vector_store"
        vector_store_name = "text_chatbot_chromadb"
        self.chroma_db_path = os.path.join(vector_store_path, vector_store_name)

        # ChromaDB ë¡œë“œ
        self.vectorstore = Chroma(
            persist_directory=self.chroma_db_path,
            embedding_function=self.embeddings,
            collection_name="text_db_0"
        )

        # ë©”íƒ€ë°ì´í„° ìºì‹œ ì„¤ì •
        self.cache_file = os.path.join(vector_store_path, "metadata_cache.pkl")

    def save_metadata_cache(self, metadata):
        """ë©”íƒ€ë°ì´í„° ìºì‹œ ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(self.cache_file), exist_ok=True)
            with open(self.cache_file, "wb") as f:
                pickle.dump(metadata, f)
        except Exception as e:
            print(f"[ERROR] ë©”íƒ€ë°ì´í„° ìºì‹œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def load_metadata_cache(self):
        """ë©”íƒ€ë°ì´í„° ìºì‹œ ë¡œë“œ"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, "rb") as f:
                    return pickle.load(f)
        except Exception as e:
            print(f"[ERROR] ìºì‹œ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

    def extract_metadata(self):
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            cached_metadata = self.load_metadata_cache()
            if cached_metadata is None:
                metadata_response = self.vectorstore.get()
                all_metadata = metadata_response.get("metadatas", []) if metadata_response else []
                self.save_metadata_cache(all_metadata)
            else:
                all_metadata = cached_metadata

            unique_sido = list(set([doc["ì‹œë„"] for doc in all_metadata if "ì‹œë„" in doc]))
            unique_sigungu = list(set([doc["ì‹œêµ°êµ¬"] for doc in all_metadata if "ì‹œêµ°êµ¬" in doc]))
            unique_local_currency = list(set([doc["ì§€ì—­í™”íëª…"] for doc in all_metadata if "ì§€ì—­í™”íëª…" in doc]))

            return unique_sido, unique_sigungu, unique_local_currency
        except Exception as e:
            print(f"[ERROR] ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return [], [], []

    def perform_qa(self, query, chroma_filter):
        """ChromaDB ê¸°ë°˜ ê²€ìƒ‰ í›„, LLMì„ ì´ìš©í•œ QA ì‹¤í–‰"""
        try:
            search_kwargs = {"k": 10}
            if chroma_filter:
                search_kwargs["filter"] = chroma_filter

            qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                retriever=self.vectorstore.as_retriever(search_kwargs=search_kwargs),
            )

            response = qa_chain.invoke(query)
            return response.get("result")
        except Exception as e:
            print(f"[ERROR] LLM ì§ˆì˜ ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"result": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

class RAGTextManager:
    def __init__(self, config):
        """RAG í…ìŠ¤íŠ¸ ëª¨ë¸ ë§¤ë‹ˆì €"""
        self.config = config
        self.model = RAGTextBase(config)

    def generate_filter_prompt(self, query: str, sido_list: list, sigungu_list: list, currency_list: list) -> str:
        """í•„í„° í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        try:
            region_empty = not sido_list and not sigungu_list
            additional_instruction = "\n- íŠ¹ì • ì§€ì—­(ê´‘ì—­ì‹œ/ë„, ì‹œêµ°êµ¬)ì— êµ­í•œëœ ì„¤ëª…ì„ í”¼í•˜ì„¸ìš”." if region_empty else ""

            query_expansion_prompt = PromptTemplate(
                input_variables=["query", "sido_list", "sigungu_list", "currency_list", "additional_instruction"],
                template="""ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê²€ìƒ‰ ì§ˆë¬¸ '{query}'ì„(ë¥¼) ë¶„ì„í•˜ì—¬ ê°€ëŠ¥í•œ í•„í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

                âœ… í˜„ì¬ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ê°’:
                - ê°€ëŠ¥í•œ ì‹œë„ ê°’: {sido_list}
                - ê°€ëŠ¥í•œ ì‹œêµ°êµ¬ ê°’: {sigungu_list}
                - ê°€ëŠ¥í•œ ì§€ì—­í™”íëª… ê°’: {currency_list}

                ğŸ’¡ í•„í„°ë§ ê·œì¹™:
                - ì‚¬ìš©ìê°€ íŠ¹ì • **ì‹œë„(ê´‘ì—­ì‹œ/ë„)**ë¥¼ ì—¬ëŸ¬ ê°œ ì–¸ê¸‰í–ˆë‹¤ë©´ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”.
                - ì‚¬ìš©ìê°€ íŠ¹ì • **ì‹œêµ°êµ¬**ë¥¼ ì—¬ëŸ¬ ê°œ ì–¸ê¸‰í–ˆë‹¤ë©´ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”.
                - ì‚¬ìš©ìê°€ íŠ¹ì • **ì§€ì—­í™”íëª…**ì„ ì—¬ëŸ¬ ê°œ ì–¸ê¸‰í–ˆë‹¤ë©´ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”.
                - JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ê³ , ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
                {additional_instruction}

                ğŸ”¥ ì˜ˆì œ ì¶œë ¥:
                ```json
                {{"ì‹œë„": ["ë¶€ì‚°", "ì„œìš¸"], "ì‹œêµ°êµ¬": ["ë¶€ì‚°ì§„êµ¬", "ê°•ë‚¨êµ¬"], "ì§€ì—­í™”íëª…": ["ë™ë°±ì „", "ì„œìš¸í˜ì´"]}}
                ```
                ë˜ëŠ”, ì¼ë¶€ë§Œ ì¡´ì¬í•  ê²½ìš°:
                ```json
                {{"ì‹œë„": ["ë¶€ì‚°"], "ì§€ì—­í™”íëª…": ["ë™ë°±ì „"]}}
                ```
                í•˜ë‚˜ì˜ ìš”ì†Œë§Œ ê°ì§€ëë‹¤ë©´:
                ```json
                {{"ì‹œë„": "ë¶€ì‚°"}}
                ```
                """
            )

            return self.model.llm.invoke(query_expansion_prompt.format(
                query=query,
                sido_list=", ".join(sido_list),
                sigungu_list=", ".join(sigungu_list),
                currency_list=", ".join(currency_list),
                additional_instruction=additional_instruction
            )).content
        except Exception as e:
            print(f"[ERROR] í•„í„° í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "{}"

    @staticmethod
    def extract_json(llm_response: str) -> dict:
        """LLM ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ"""
        try:
            json_match = re.search(r'```json\n(.*?)\n```', llm_response, re.DOTALL)
            json_text = json_match.group(1) if json_match else llm_response

            return json.loads(json_text)
        except json.JSONDecodeError as e:
            print(f"[ERROR] JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {}

    @staticmethod
    def transform_filters_to_chroma(filters):
        """LLMì´ ìƒì„±í•œ í•„í„°ë¥¼ ChromaDBì˜ $in, $and í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            if not filters:
                return None

            chroma_filters = [{key: {"$in": value} if isinstance(value, list) else {"$eq": value}} for key, value in filters.items()]
            return {"$and": chroma_filters} if len(chroma_filters) > 1 else chroma_filters[0]
        except Exception as e:
            print(f"[ERROR] í•„í„° ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
